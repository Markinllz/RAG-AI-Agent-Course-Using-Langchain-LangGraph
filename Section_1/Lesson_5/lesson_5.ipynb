{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3a0d371",
   "metadata": {},
   "source": [
    "# Text Splitting and txt Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e80d663e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /opt/anaconda3/envs/ai_rag/lib/python3.13/site-packages (0.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/ai_rag/lib/python3.13/site-packages (from tiktoken) (2025.9.18)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/anaconda3/envs/ai_rag/lib/python3.13/site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/ai_rag/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/ai_rag/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/ai_rag/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/ai_rag/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "009d405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File some_text.txt created!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "text_content = \"\"\"\n",
    "This is a very long sentence that contains many words and goes on for a very long time to demonstrate how character text splitter works with overlap when the text is longer than the chunk size and needs to be split across multiple chunks while maintaining some overlap between them for better context preservation and understanding of the content that spans across chunk boundaries eowoeiwoefhoewhofweoifhoiweohfwoiefoweofhweohfowehofhowehfioweohifhiowehoifweiohfiohweofhwhiofhiofwhiofhoiwefhoiweohifehoiwfhoiwoheifohiewfhoiwehoifhoiewfhoiweohiefoihwefiohwohfewhoioehwfhoewohfweoifowehofewhofoweofwefoweh eiorfjoierjoferoie jerio jio ge jgoe or gergjeorjgoejr jg oejrgo eorj goer goeroigeoroj goj erjogoergijoer roefer iojgojre ejog ejorgo oergoj ejrgjeriogjoierjogerogejrgeor jgrejgjreogoergoerjoigoiergj erjgoe joegerjgieorgoerjogjergijeor giojejrgeorgoerojgejorjo ejogeoji ooegojgerogro.\n",
    "\n",
    "Another very long sentence that also contains many words and continues for a long time to show how the overlap mechanism works when splitting text that is longer than the specified chunk size and needs to be divided into multiple parts while keeping some overlapping content between adjacent chunks for better text processing and analysis.\n",
    "\n",
    "This is the third very long sentence that demonstrates the same concept with many words and continues for a long time to illustrate how character text splitter handles long text by splitting it into chunks with overlap when the content exceeds the specified chunk size limit.\n",
    "\"\"\"\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "with open(\"data/some_text.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(text_content)\n",
    "\n",
    "print(\"File some_text.txt created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "53c24dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "def process_text(file_path: str) -> List[Document]:\n",
    "\n",
    "    txt_loader = TextLoader(file_path,encoding='utf-8')\n",
    "    txt_doc = txt_loader.load()\n",
    "\n",
    "    return txt_doc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "06ed4693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data/some_text.txt'}, page_content='\\nThis is a very long sentence that contains many words and goes on for a very long time to demonstrate how character text splitter works with overlap when the text is longer than the chunk size and needs to be split across multiple chunks while maintaining some overlap between them for better context preservation and understanding of the content that spans across chunk boundaries eowoeiwoefhoewhofweoifhoiweohfwoiefoweofhweohfowehofhowehfioweohifhiowehoifweiohfiohweofhwhiofhiofwhiofhoiwefhoiweohifehoiwfhoiwoheifohiewfhoiwehoifhoiewfhoiweohiefoihwefiohwohfewhoioehwfhoewohfweoifowehofewhofoweofwefoweh eiorfjoierjoferoie jerio jio ge jgoe or gergjeorjgoejr jg oejrgo eorj goer goeroigeoroj goj erjogoergijoer roefer iojgojre ejog ejorgo oergoj ejrgjeriogjoierjogerogejrgeor jgrejgjreogoergoerjoigoiergj erjgoe joegerjgieorgoerjogjergijeor giojejrgeorgoerojgejorjo ejogeoji ooegojgerogro.\\n\\nAnother very long sentence that also contains many words and continues for a long time to show how the overlap mechanism works when splitting text that is longer than the specified chunk size and needs to be divided into multiple parts while keeping some overlapping content between adjacent chunks for better text processing and analysis.\\n\\nThis is the third very long sentence that demonstrates the same concept with many words and continues for a long time to illustrate how character text splitter handles long text by splitting it into chunks with overlap when the content exceeds the specified chunk size limit.\\n')]\n",
      "\n",
      "This is a very long sentence that contains many words and goes on for a very long time to demonstrate how character text splitter works with overlap when the text is longer than the chunk size and needs to be split across multiple chunks while maintaining some overlap between them for better context preservation and understanding of the content that spans across chunk boundaries eowoeiwoefhoewhofweoifhoiweohfwoiefoweofhweohfowehofhowehfioweohifhiowehoifweiohfiohweofhwhiofhiofwhiofhoiwefhoiweohi\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import (\n",
    "    CharacterTextSplitter,\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    TokenTextSplitter\n",
    ")\n",
    "\n",
    "current_docs = process_text('data/some_text.txt')\n",
    "\n",
    "print(current_docs)\n",
    "print(current_docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5994c584",
   "metadata": {},
   "source": [
    "## Character-bases splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "01e93a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1.\n",
    "text = current_docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2a5791b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_text_splitters.base:Created a chunk of size 222, which is longer than the specified 100\n"
     ]
    }
   ],
   "source": [
    "char_splitter = CharacterTextSplitter(\n",
    "    separator = \" \", # Split on new lines\n",
    "    chunk_size = 100, # Max chunk length\n",
    "    chunk_overlap =30, # Overlap between chunks\n",
    "    length_function = len # How to count chunk size\n",
    ")\n",
    "\n",
    "char_chunks = char_splitter.split_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "be363e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a very long sentence that contains many words and goes on for a very long time to\n",
      "------------\n",
      "on for a very long time to demonstrate how character text splitter works with overlap when the text\n",
      "------------\n",
      "with overlap when the text is longer than the chunk size and needs to be split across multiple\n"
     ]
    }
   ],
   "source": [
    "print(char_chunks[0])\n",
    "print(\"------------\")\n",
    "print(char_chunks[1])\n",
    "print(\"------------\")\n",
    "print(char_chunks[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c8c8b6",
   "metadata": {},
   "source": [
    "## Recursive Text Splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c125159f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6346260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursively iterate throw all separators and chunking the text\n",
    "RecSplitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \"], # Recursive iteration throw all spliters\n",
    "    chunk_size = 250, # Max chunk length\n",
    "    chunk_overlap =50, # Overlap between chunks\n",
    "    length_function = len # How to count chunk size\n",
    ")\n",
    "\n",
    "rec_chunks = RecSplitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d9a54dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a very long sentence that contains many words and goes on for a very long time to demonstrate how character text splitter works with overlap when the text is longer than the chunk size and needs to be split across multiple chunks while\n",
      "------------\n",
      "needs to be split across multiple chunks while maintaining some overlap between them for better context preservation and understanding of the content that spans across chunk boundaries\n",
      "------------\n",
      "across chunk boundaries eowoeiwoefhoewhofweoifhoiweohfwoiefoweofhweohfowehofhowehfioweohifhiowehoifweiohfiohweofhwhiofhiofwhiofhoiwefhoiweohifehoiwfhoiwoheifohiewfhoiwehoifhoiewfhoiweohiefoihwefiohwohfewhoioehwfhoewohfweoifowehofewhofoweofwefoweh\n"
     ]
    }
   ],
   "source": [
    "print(rec_chunks[0])\n",
    "print(\"------------\")\n",
    "print(rec_chunks[1])\n",
    "print(\"------------\")\n",
    "print(rec_chunks[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe108f6",
   "metadata": {},
   "source": [
    "## Token Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a14d9805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token text splitter working like Character splitter, but instead of separators it uses tokens like LLM models\n",
    "\n",
    "\n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size = 200,\n",
    "    chunk_overlap = 50,\n",
    "    model_name=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "token_chunks = token_splitter.split_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "07d14c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is a very long sentence that contains many words and goes on for a very long time to demonstrate how character text splitter works with overlap when the text is longer than the chunk size and needs to be split across multiple chunks while maintaining some overlap between them for better context preservation and understanding of the content that spans across chunk boundaries eowoeiwoefhoewhofweoifhoiweohfwoiefoweofhweohfowehofhowehfioweohifhiowehoifweiohfiohweofhwhiofhiofwhiofhoiwefhoiweohifehoiwfhoiwoheifohiewfhoiwehoifhoiewfhoiweohiefoihwefiohwohfewhoioehwfhoewohfweoifowehofewhofoweofwefoweh eiorfjoierjoferoie jerio jio ge jgoe\n",
      "------------\n",
      "ohiefoihwefiohwohfewhoioehwfhoewohfweoifowehofewhofoweofwefoweh eiorfjoierjoferoie jerio jio ge jgoe or gergjeorjgoejr jg oejrgo eorj goer goeroigeoroj goj erjogoergijoer roefer iojgojre ejog ejorgo oergoj ejrgjeriogjoierjogerogejrgeor jgrejgjreogoergoerjoigoiergj erjgoe joegerjgieorgoerjogjergijeor giojejrgeorgoerojgejorjo ejogeoji ooegojgerogro.\n",
      "\n",
      "Another very long sentence that also contains many words and continues for a long time to show how the overlap mechanism works when splitting text that is longer than the specified chunk\n",
      "------------\n",
      "oerojgejorjo ejogeoji ooegojgerogro.\n",
      "\n",
      "Another very long sentence that also contains many words and continues for a long time to show how the overlap mechanism works when splitting text that is longer than the specified chunk size and needs to be divided into multiple parts while keeping some overlapping content between adjacent chunks for better text processing and analysis.\n",
      "\n",
      "This is the third very long sentence that demonstrates the same concept with many words and continues for a long time to illustrate how character text splitter handles long text by splitting it into chunks with overlap when the content exceeds the specified chunk size limit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(token_chunks[0])\n",
    "print(\"------------\")\n",
    "print(token_chunks[1])\n",
    "print(\"------------\")\n",
    "print(token_chunks[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "25c5e40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thats all about chunking, in section 3 we will discuss senior methods of chunking, like chunking using semantic information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
